---
title: "R Squared"
description: |
  R Squared as a measure of model fit
author:
  - name: Colin Miner 
date: "`r Sys.Date()`"
output: distill::distill_article
---

*R-squared can be arbitrarily close to 1 when the model is totally wrong.*

When a measure indicates that a model is performing poorly, it will prompt the user to investigate the model for problems. This may waste time, but is less of a problem than if the measure gives a false positive and makes it seem like the model is performing well. This can cause a user to continue on with the bad model and create more problems down the road. 

```{r, echo=TRUE}
set.seed(1)
# our predictor is data from an exponential distribution
x <- rexp(50,rate=0.005)
# non-linear data generation
y <- (x-1)^2 * runif(50, min=0.8, max=1.2) 

# clearly non-linear
plot(x,y)				     
```

```{r,echo=TRUE}
summary(lm(y ~ x))$r.squared
```

Even adjusted and predictive R^2 are not much better:

```{r,echo=TRUE}
#Adjusted R^2
summary(lm(y ~ x))$adj.r.squared

#PRESS - predicted residual sums of squares

PRESS <- function(linear.model) {
  #' calculate the predictive residuals
  pr <- residuals(linear.model)/(1-lm.influence(linear.model)$hat)
  #' calculate the PRESS
  PRESS <- sum(pr^2)
  
  return(PRESS)
}

pred_r_squared <- function(linear.model) {
  #' Use anova() to get the sum of squares for the linear model
  lm.anova <- anova(linear.model)
  #' Calculate the total sum of squares
  tss <- sum(lm.anova$'Sum Sq')
  # Calculate the predictive R^2
  pred.r.squared <- 1-PRESS(linear.model)/(tss)
  
  return(pred.r.squared)
}

model <- lm(y ~ x)  
pred_r_squared(model)
```


There is no perfect solution, but relying on a single measure for model fit always leaves a chance of something going wrong. Using multiple measures helps, as does simply graphing the data and visually judging the model.