{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T01:09:55-06:00"
    },
    {
      "path": "Final.html",
      "title": "Final Project",
      "description": "Using gradiant boosting to predict heart problems\n",
      "author": [
        {
          "name": "Colin Miner",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\n\r\n\r\n1. A description of your data and where you found it and what you are predicting\r\nThe data concerns patients who are at risk for heart disease, and contains multiple attributes that can be risk factors or red flags for heart disease. It was developed by combining five other publicly available heart datasets and eliminating the duplicates. I will be using it to predict if a patient has heart disease.\r\nSource: https://www.kaggle.com/fedesoriano/heart-failure-prediction\r\n2. Descriptive statistics - small discussion…are the skewed or are there outliers etc.\r\nThe patient records are highly skewed towards men, and towards patients with <= 120 mg/dl fasting blood sugar. The resting BP has a high kurtosis, partly because of one major outlier with no resting BP, and 20 records (~2%) exceeding 180 bpm.\r\nThe average patient age is 53, which is useful for this prediction as young people rarely have detectable heart problems on average.\r\nThe cholesterol levels vary pretty widely, and I predict will be an important variable.\r\nBut overall the dataset is very clean.\r\n\r\n\r\nheart <- read.csv(\"data/Heart.csv\",sep=',')\r\npsych::describe(heart)\r\n\r\n\r\n                vars   n   mean     sd median trimmed   mad  min\r\nAge                1 918  53.51   9.43   54.0   53.71 10.38 28.0\r\nSex*               2 918   1.79   0.41    2.0    1.86  0.00  1.0\r\nChestPainType*     3 918   1.78   0.96    1.0    1.66  0.00  1.0\r\nRestingBP          4 918 132.40  18.51  130.0  131.50 14.83  0.0\r\nCholesterol        5 918 198.80 109.38  223.0  204.41 68.20  0.0\r\nFastingBS          6 918   0.23   0.42    0.0    0.17  0.00  0.0\r\nRestingECG*        7 918   1.99   0.63    2.0    1.99  0.00  1.0\r\nMaxHR              8 918 136.81  25.46  138.0  137.23 26.69 60.0\r\nExerciseAngina*    9 918   1.40   0.49    1.0    1.38  0.00  1.0\r\nOldpeak           10 918   0.89   1.07    0.6    0.74  0.89 -2.6\r\nST_Slope*         11 918   2.36   0.61    2.0    2.41  0.00  1.0\r\nHeartDisease      12 918   0.55   0.50    1.0    0.57  0.00  0.0\r\n                  max range  skew kurtosis   se\r\nAge              77.0  49.0 -0.20    -0.40 0.31\r\nSex*              2.0   1.0 -1.42     0.02 0.01\r\nChestPainType*    4.0   3.0  0.79    -0.72 0.03\r\nRestingBP       200.0 200.0  0.18     3.23 0.61\r\nCholesterol     603.0 603.0 -0.61     0.10 3.61\r\nFastingBS         1.0   1.0  1.26    -0.41 0.01\r\nRestingECG*       3.0   2.0  0.01    -0.50 0.02\r\nMaxHR           202.0 142.0 -0.14    -0.46 0.84\r\nExerciseAngina*   2.0   1.0  0.39    -1.85 0.02\r\nOldpeak           6.2   8.8  1.02     1.18 0.04\r\nST_Slope*         3.0   2.0 -0.38    -0.67 0.02\r\nHeartDisease      1.0   1.0 -0.21    -1.96 0.02\r\n\r\n3. Describe your machine learning model (short description)\r\nGradient boosting is very similar to random forests, in that it uses many decision trees to develop a better prediction model. It differs in how the trees are created and how the results are combined. The decision trees are developed iteratively with each new tree helping to fix the errors of the previous tree, to form an optimal model.\r\n4. Split data, run model, and find the results\r\n\r\n\r\nheart<-heart%>%\r\n  mutate(prediction=if_else(HeartDisease==1,\"YES\",\"NO\"))\r\n\r\nset.seed(1)\r\n#lets split the data 60/40\r\n\r\ntrainIndex <- createDataPartition(heart$prediction, p = .6, list = FALSE, times = 1)\r\n\r\n#grab the data\r\nheartTrain <- heart[ trainIndex,]\r\nheartTest  <- heart[-trainIndex,]\r\n\r\nset.seed(1)\r\n\r\nheartXGB<- train(\r\n  form = prediction~Age+Sex+ChestPainType+RestingBP+Cholesterol+FastingBS+RestingECG+MaxHR+ExerciseAngina,\r\n  data = heartTrain,\r\n  #here we add classProbs because we want probs\r\n  trControl = trainControl(method = \"cv\", number = 10,\r\n                           classProbs =  TRUE),\r\n  method = \"gbm\",\r\n  tuneLength = 20,\r\n  verbose=FALSE)\r\n\r\n#heartXGB\r\nknitr::kable(heartXGB$bestTune)\r\n\r\n\r\n\r\nn.trees\r\ninteraction.depth\r\nshrinkage\r\nn.minobsinnode\r\n21\r\n50\r\n2\r\n0.1\r\n10\r\n\r\nplot(heartXGB)\r\n\r\n\r\n\r\n#Results\r\nheartXGB_Pred<-predict(heartXGB,heartTest,type=\"prob\")\r\n\r\nknitr::kable(heartXGB_Pred)%>%\r\n  kableExtra::kable_styling(\"striped\")%>%\r\n  kableExtra::scroll_box(width = \"50%\",height=\"300px\")\r\n\r\n\r\n\r\n\r\nNO\r\n\r\n\r\nYES\r\n\r\n\r\n0.7507342\r\n\r\n\r\n0.2492658\r\n\r\n\r\n0.5858262\r\n\r\n\r\n0.4141738\r\n\r\n\r\n0.8609541\r\n\r\n\r\n0.1390459\r\n\r\n\r\n0.9320542\r\n\r\n\r\n0.0679458\r\n\r\n\r\n0.8010095\r\n\r\n\r\n0.1989905\r\n\r\n\r\n0.8570145\r\n\r\n\r\n0.1429855\r\n\r\n\r\n0.9035996\r\n\r\n\r\n0.0964004\r\n\r\n\r\n0.9159566\r\n\r\n\r\n0.0840434\r\n\r\n\r\n0.9211705\r\n\r\n\r\n0.0788295\r\n\r\n\r\n0.8700441\r\n\r\n\r\n0.1299559\r\n\r\n\r\n0.1537220\r\n\r\n\r\n0.8462780\r\n\r\n\r\n0.8436572\r\n\r\n\r\n0.1563428\r\n\r\n\r\n0.5635651\r\n\r\n\r\n0.4364349\r\n\r\n\r\n0.7074929\r\n\r\n\r\n0.2925071\r\n\r\n\r\n0.8912108\r\n\r\n\r\n0.1087892\r\n\r\n\r\n0.0927409\r\n\r\n\r\n0.9072591\r\n\r\n\r\n0.4190416\r\n\r\n\r\n0.5809584\r\n\r\n\r\n0.2187463\r\n\r\n\r\n0.7812537\r\n\r\n\r\n0.7630707\r\n\r\n\r\n0.2369293\r\n\r\n\r\n0.8272557\r\n\r\n\r\n0.1727443\r\n\r\n\r\n0.6523599\r\n\r\n\r\n0.3476401\r\n\r\n\r\n0.1626365\r\n\r\n\r\n0.8373635\r\n\r\n\r\n0.2803600\r\n\r\n\r\n0.7196400\r\n\r\n\r\n0.1574977\r\n\r\n\r\n0.8425023\r\n\r\n\r\n0.8877883\r\n\r\n\r\n0.1122117\r\n\r\n\r\n0.1067769\r\n\r\n\r\n0.8932231\r\n\r\n\r\n0.6234960\r\n\r\n\r\n0.3765040\r\n\r\n\r\n0.3848048\r\n\r\n\r\n0.6151952\r\n\r\n\r\n0.1356804\r\n\r\n\r\n0.8643196\r\n\r\n\r\n0.3576947\r\n\r\n\r\n0.6423053\r\n\r\n\r\n0.7058471\r\n\r\n\r\n0.2941529\r\n\r\n\r\n0.8012456\r\n\r\n\r\n0.1987544\r\n\r\n\r\n0.4138249\r\n\r\n\r\n0.5861751\r\n\r\n\r\n0.8565337\r\n\r\n\r\n0.1434663\r\n\r\n\r\n0.0907465\r\n\r\n\r\n0.9092535\r\n\r\n\r\n0.6210802\r\n\r\n\r\n0.3789198\r\n\r\n\r\n0.6555423\r\n\r\n\r\n0.3444577\r\n\r\n\r\n0.1296611\r\n\r\n\r\n0.8703389\r\n\r\n\r\n0.9066209\r\n\r\n\r\n0.0933791\r\n\r\n\r\n0.7003475\r\n\r\n\r\n0.2996525\r\n\r\n\r\n0.7739741\r\n\r\n\r\n0.2260259\r\n\r\n\r\n0.1228739\r\n\r\n\r\n0.8771261\r\n\r\n\r\n0.4636578\r\n\r\n\r\n0.5363422\r\n\r\n\r\n0.7411570\r\n\r\n\r\n0.2588430\r\n\r\n\r\n0.2691004\r\n\r\n\r\n0.7308996\r\n\r\n\r\n0.6963815\r\n\r\n\r\n0.3036185\r\n\r\n\r\n0.7466081\r\n\r\n\r\n0.2533919\r\n\r\n\r\n0.8890509\r\n\r\n\r\n0.1109491\r\n\r\n\r\n0.8793534\r\n\r\n\r\n0.1206466\r\n\r\n\r\n0.2440972\r\n\r\n\r\n0.7559028\r\n\r\n\r\n0.8305378\r\n\r\n\r\n0.1694622\r\n\r\n\r\n0.4427153\r\n\r\n\r\n0.5572847\r\n\r\n\r\n0.9011905\r\n\r\n\r\n0.0988095\r\n\r\n\r\n0.8287355\r\n\r\n\r\n0.1712645\r\n\r\n\r\n0.8519034\r\n\r\n\r\n0.1480966\r\n\r\n\r\n0.2301914\r\n\r\n\r\n0.7698086\r\n\r\n\r\n0.8288432\r\n\r\n\r\n0.1711568\r\n\r\n\r\n0.9452042\r\n\r\n\r\n0.0547958\r\n\r\n\r\n0.2173806\r\n\r\n\r\n0.7826194\r\n\r\n\r\n0.6135594\r\n\r\n\r\n0.3864406\r\n\r\n\r\n0.9084961\r\n\r\n\r\n0.0915039\r\n\r\n\r\n0.8966879\r\n\r\n\r\n0.1033121\r\n\r\n\r\n0.7213679\r\n\r\n\r\n0.2786321\r\n\r\n\r\n0.8834523\r\n\r\n\r\n0.1165477\r\n\r\n\r\n0.4893148\r\n\r\n\r\n0.5106852\r\n\r\n\r\n0.1064813\r\n\r\n\r\n0.8935187\r\n\r\n\r\n0.8261816\r\n\r\n\r\n0.1738184\r\n\r\n\r\n0.6844663\r\n\r\n\r\n0.3155337\r\n\r\n\r\n0.2190962\r\n\r\n\r\n0.7809038\r\n\r\n\r\n0.8466965\r\n\r\n\r\n0.1533035\r\n\r\n\r\n0.1867041\r\n\r\n\r\n0.8132959\r\n\r\n\r\n0.2219366\r\n\r\n\r\n0.7780634\r\n\r\n\r\n0.4912227\r\n\r\n\r\n0.5087773\r\n\r\n\r\n0.8480702\r\n\r\n\r\n0.1519298\r\n\r\n\r\n0.1626365\r\n\r\n\r\n0.8373635\r\n\r\n\r\n0.8484585\r\n\r\n\r\n0.1515415\r\n\r\n\r\n0.2152907\r\n\r\n\r\n0.7847093\r\n\r\n\r\n0.3961581\r\n\r\n\r\n0.6038419\r\n\r\n\r\n0.4012498\r\n\r\n\r\n0.5987502\r\n\r\n\r\n0.8164061\r\n\r\n\r\n0.1835939\r\n\r\n\r\n0.9479545\r\n\r\n\r\n0.0520455\r\n\r\n\r\n0.1537220\r\n\r\n\r\n0.8462780\r\n\r\n\r\n0.5626346\r\n\r\n\r\n0.4373654\r\n\r\n\r\n0.9204479\r\n\r\n\r\n0.0795521\r\n\r\n\r\n0.8447696\r\n\r\n\r\n0.1552304\r\n\r\n\r\n0.4782911\r\n\r\n\r\n0.5217089\r\n\r\n\r\n0.4174050\r\n\r\n\r\n0.5825950\r\n\r\n\r\n0.2247784\r\n\r\n\r\n0.7752216\r\n\r\n\r\n0.8852949\r\n\r\n\r\n0.1147051\r\n\r\n\r\n0.1127894\r\n\r\n\r\n0.8872106\r\n\r\n\r\n0.7384616\r\n\r\n\r\n0.2615384\r\n\r\n\r\n0.6155694\r\n\r\n\r\n0.3844306\r\n\r\n\r\n0.8590056\r\n\r\n\r\n0.1409944\r\n\r\n\r\n0.7123771\r\n\r\n\r\n0.2876229\r\n\r\n\r\n0.5333710\r\n\r\n\r\n0.4666290\r\n\r\n\r\n0.9208382\r\n\r\n\r\n0.0791618\r\n\r\n\r\n0.8699004\r\n\r\n\r\n0.1300996\r\n\r\n\r\n0.8861057\r\n\r\n\r\n0.1138943\r\n\r\n\r\n0.6762306\r\n\r\n\r\n0.3237694\r\n\r\n\r\n0.2063093\r\n\r\n\r\n0.7936907\r\n\r\n\r\n0.6900796\r\n\r\n\r\n0.3099204\r\n\r\n\r\n0.1646915\r\n\r\n\r\n0.8353085\r\n\r\n\r\n0.9106234\r\n\r\n\r\n0.0893766\r\n\r\n\r\n0.0945586\r\n\r\n\r\n0.9054414\r\n\r\n\r\n0.6047780\r\n\r\n\r\n0.3952220\r\n\r\n\r\n0.2846885\r\n\r\n\r\n0.7153115\r\n\r\n\r\n0.1148480\r\n\r\n\r\n0.8851520\r\n\r\n\r\n0.5982234\r\n\r\n\r\n0.4017766\r\n\r\n\r\n0.5210815\r\n\r\n\r\n0.4789185\r\n\r\n\r\n0.7793440\r\n\r\n\r\n0.2206560\r\n\r\n\r\n0.8111783\r\n\r\n\r\n0.1888217\r\n\r\n\r\n0.8151163\r\n\r\n\r\n0.1848837\r\n\r\n\r\n0.2033527\r\n\r\n\r\n0.7966473\r\n\r\n\r\n0.8313005\r\n\r\n\r\n0.1686995\r\n\r\n\r\n0.1863270\r\n\r\n\r\n0.8136730\r\n\r\n\r\n0.1038005\r\n\r\n\r\n0.8961995\r\n\r\n\r\n0.7072034\r\n\r\n\r\n0.2927966\r\n\r\n\r\n0.6800630\r\n\r\n\r\n0.3199370\r\n\r\n\r\n0.4762416\r\n\r\n\r\n0.5237584\r\n\r\n\r\n0.1587309\r\n\r\n\r\n0.8412691\r\n\r\n\r\n0.8591348\r\n\r\n\r\n0.1408652\r\n\r\n\r\n0.6779897\r\n\r\n\r\n0.3220103\r\n\r\n\r\n0.8213474\r\n\r\n\r\n0.1786526\r\n\r\n\r\n0.7079429\r\n\r\n\r\n0.2920571\r\n\r\n\r\n0.8180653\r\n\r\n\r\n0.1819347\r\n\r\n\r\n0.8063273\r\n\r\n\r\n0.1936727\r\n\r\n\r\n0.8944087\r\n\r\n\r\n0.1055913\r\n\r\n\r\n0.0555708\r\n\r\n\r\n0.9444292\r\n\r\n\r\n0.0891352\r\n\r\n\r\n0.9108648\r\n\r\n\r\n0.1222232\r\n\r\n\r\n0.8777768\r\n\r\n\r\n0.4391289\r\n\r\n\r\n0.5608711\r\n\r\n\r\n0.1669742\r\n\r\n\r\n0.8330258\r\n\r\n\r\n0.3821621\r\n\r\n\r\n0.6178379\r\n\r\n\r\n0.1145524\r\n\r\n\r\n0.8854476\r\n\r\n\r\n0.1600176\r\n\r\n\r\n0.8399824\r\n\r\n\r\n0.1378815\r\n\r\n\r\n0.8621185\r\n\r\n\r\n0.1039625\r\n\r\n\r\n0.8960375\r\n\r\n\r\n0.2247573\r\n\r\n\r\n0.7752427\r\n\r\n\r\n0.3444440\r\n\r\n\r\n0.6555560\r\n\r\n\r\n0.1261780\r\n\r\n\r\n0.8738220\r\n\r\n\r\n0.4062203\r\n\r\n\r\n0.5937797\r\n\r\n\r\n0.0578753\r\n\r\n\r\n0.9421247\r\n\r\n\r\n0.0707245\r\n\r\n\r\n0.9292755\r\n\r\n\r\n0.1853132\r\n\r\n\r\n0.8146868\r\n\r\n\r\n0.1167464\r\n\r\n\r\n0.8832536\r\n\r\n\r\n0.1117411\r\n\r\n\r\n0.8882589\r\n\r\n\r\n0.1213346\r\n\r\n\r\n0.8786654\r\n\r\n\r\n0.0890725\r\n\r\n\r\n0.9109275\r\n\r\n\r\n0.1123117\r\n\r\n\r\n0.8876883\r\n\r\n\r\n0.1675122\r\n\r\n\r\n0.8324878\r\n\r\n\r\n0.1396959\r\n\r\n\r\n0.8603041\r\n\r\n\r\n0.1197241\r\n\r\n\r\n0.8802759\r\n\r\n\r\n0.0798550\r\n\r\n\r\n0.9201450\r\n\r\n\r\n0.1006308\r\n\r\n\r\n0.8993692\r\n\r\n\r\n0.0590940\r\n\r\n\r\n0.9409060\r\n\r\n\r\n0.2145949\r\n\r\n\r\n0.7854051\r\n\r\n\r\n0.1842161\r\n\r\n\r\n0.8157839\r\n\r\n\r\n0.2103856\r\n\r\n\r\n0.7896144\r\n\r\n\r\n0.0807143\r\n\r\n\r\n0.9192857\r\n\r\n\r\n0.0725923\r\n\r\n\r\n0.9274077\r\n\r\n\r\n0.0590940\r\n\r\n\r\n0.9409060\r\n\r\n\r\n0.1386429\r\n\r\n\r\n0.8613571\r\n\r\n\r\n0.1210813\r\n\r\n\r\n0.8789187\r\n\r\n\r\n0.0590940\r\n\r\n\r\n0.9409060\r\n\r\n\r\n0.0758256\r\n\r\n\r\n0.9241744\r\n\r\n\r\n0.1399558\r\n\r\n\r\n0.8600442\r\n\r\n\r\n0.0727683\r\n\r\n\r\n0.9272317\r\n\r\n\r\n0.1114496\r\n\r\n\r\n0.8885504\r\n\r\n\r\n0.1213346\r\n\r\n\r\n0.8786654\r\n\r\n\r\n0.1230628\r\n\r\n\r\n0.8769372\r\n\r\n\r\n0.1396959\r\n\r\n\r\n0.8603041\r\n\r\n\r\n0.0504067\r\n\r\n\r\n0.9495933\r\n\r\n\r\n0.2635922\r\n\r\n\r\n0.7364078\r\n\r\n\r\n0.0689166\r\n\r\n\r\n0.9310834\r\n\r\n\r\n0.2771034\r\n\r\n\r\n0.7228966\r\n\r\n\r\n0.1853132\r\n\r\n\r\n0.8146868\r\n\r\n\r\n0.1024176\r\n\r\n\r\n0.8975824\r\n\r\n\r\n0.0949484\r\n\r\n\r\n0.9050516\r\n\r\n\r\n0.0653726\r\n\r\n\r\n0.9346274\r\n\r\n\r\n0.1729420\r\n\r\n\r\n0.8270580\r\n\r\n\r\n0.1314399\r\n\r\n\r\n0.8685601\r\n\r\n\r\n0.6812296\r\n\r\n\r\n0.3187704\r\n\r\n\r\n0.8066807\r\n\r\n\r\n0.1933193\r\n\r\n\r\n0.0807143\r\n\r\n\r\n0.9192857\r\n\r\n\r\n0.0865476\r\n\r\n\r\n0.9134524\r\n\r\n\r\n0.1264552\r\n\r\n\r\n0.8735448\r\n\r\n\r\n0.0807143\r\n\r\n\r\n0.9192857\r\n\r\n\r\n0.1194258\r\n\r\n\r\n0.8805742\r\n\r\n\r\n0.1395449\r\n\r\n\r\n0.8604551\r\n\r\n\r\n0.1038700\r\n\r\n\r\n0.8961300\r\n\r\n\r\n0.0895754\r\n\r\n\r\n0.9104246\r\n\r\n\r\n0.1039480\r\n\r\n\r\n0.8960520\r\n\r\n\r\n0.2716259\r\n\r\n\r\n0.7283741\r\n\r\n\r\n0.1179129\r\n\r\n\r\n0.8820871\r\n\r\n\r\n0.1491924\r\n\r\n\r\n0.8508076\r\n\r\n\r\n0.1388309\r\n\r\n\r\n0.8611691\r\n\r\n\r\n0.8990940\r\n\r\n\r\n0.1009060\r\n\r\n\r\n0.1263164\r\n\r\n\r\n0.8736836\r\n\r\n\r\n0.5583313\r\n\r\n\r\n0.4416687\r\n\r\n\r\n0.1136751\r\n\r\n\r\n0.8863249\r\n\r\n\r\n0.0807143\r\n\r\n\r\n0.9192857\r\n\r\n\r\n0.1946480\r\n\r\n\r\n0.8053520\r\n\r\n\r\n0.2174783\r\n\r\n\r\n0.7825217\r\n\r\n\r\n0.2790098\r\n\r\n\r\n0.7209902\r\n\r\n\r\n0.0833645\r\n\r\n\r\n0.9166355\r\n\r\n\r\n0.1672610\r\n\r\n\r\n0.8327390\r\n\r\n\r\n0.1878083\r\n\r\n\r\n0.8121917\r\n\r\n\r\n0.1006791\r\n\r\n\r\n0.8993209\r\n\r\n\r\n0.1414432\r\n\r\n\r\n0.8585568\r\n\r\n\r\n0.7906247\r\n\r\n\r\n0.2093753\r\n\r\n\r\n0.0977524\r\n\r\n\r\n0.9022476\r\n\r\n\r\n0.1369084\r\n\r\n\r\n0.8630916\r\n\r\n\r\n0.4923297\r\n\r\n\r\n0.5076703\r\n\r\n\r\n0.4601499\r\n\r\n\r\n0.5398501\r\n\r\n\r\n0.1956690\r\n\r\n\r\n0.8043310\r\n\r\n\r\n0.1277611\r\n\r\n\r\n0.8722389\r\n\r\n\r\n0.2101630\r\n\r\n\r\n0.7898370\r\n\r\n\r\n0.1044035\r\n\r\n\r\n0.8955965\r\n\r\n\r\n0.3112380\r\n\r\n\r\n0.6887620\r\n\r\n\r\n0.0725923\r\n\r\n\r\n0.9274077\r\n\r\n\r\n0.1100612\r\n\r\n\r\n0.8899388\r\n\r\n\r\n0.3406569\r\n\r\n\r\n0.6593431\r\n\r\n\r\n0.2815727\r\n\r\n\r\n0.7184273\r\n\r\n\r\n0.5503820\r\n\r\n\r\n0.4496180\r\n\r\n\r\n0.7551557\r\n\r\n\r\n0.2448443\r\n\r\n\r\n0.6636095\r\n\r\n\r\n0.3363905\r\n\r\n\r\n0.1669891\r\n\r\n\r\n0.8330109\r\n\r\n\r\n0.0910796\r\n\r\n\r\n0.9089204\r\n\r\n\r\n0.8282701\r\n\r\n\r\n0.1717299\r\n\r\n\r\n0.1522243\r\n\r\n\r\n0.8477757\r\n\r\n\r\n0.1291230\r\n\r\n\r\n0.8708770\r\n\r\n\r\n0.0884662\r\n\r\n\r\n0.9115338\r\n\r\n\r\n0.1457217\r\n\r\n\r\n0.8542783\r\n\r\n\r\n0.1201923\r\n\r\n\r\n0.8798077\r\n\r\n\r\n0.1264501\r\n\r\n\r\n0.8735499\r\n\r\n\r\n0.0850291\r\n\r\n\r\n0.9149709\r\n\r\n\r\n0.1056129\r\n\r\n\r\n0.8943871\r\n\r\n\r\n0.0907234\r\n\r\n\r\n0.9092766\r\n\r\n\r\n0.8657174\r\n\r\n\r\n0.1342826\r\n\r\n\r\n0.1264501\r\n\r\n\r\n0.8735499\r\n\r\n\r\n0.4795103\r\n\r\n\r\n0.5204897\r\n\r\n\r\n0.0983242\r\n\r\n\r\n0.9016758\r\n\r\n\r\n0.1392298\r\n\r\n\r\n0.8607702\r\n\r\n\r\n0.6842441\r\n\r\n\r\n0.3157559\r\n\r\n\r\n0.3253857\r\n\r\n\r\n0.6746143\r\n\r\n\r\n0.1447975\r\n\r\n\r\n0.8552025\r\n\r\n\r\n0.1513967\r\n\r\n\r\n0.8486033\r\n\r\n\r\n0.1190172\r\n\r\n\r\n0.8809828\r\n\r\n\r\n0.6166404\r\n\r\n\r\n0.3833596\r\n\r\n\r\n0.0888121\r\n\r\n\r\n0.9111879\r\n\r\n\r\n0.2855564\r\n\r\n\r\n0.7144436\r\n\r\n\r\n0.5823199\r\n\r\n\r\n0.4176801\r\n\r\n\r\n0.5293805\r\n\r\n\r\n0.4706195\r\n\r\n\r\n0.5514095\r\n\r\n\r\n0.4485905\r\n\r\n\r\n0.8772877\r\n\r\n\r\n0.1227123\r\n\r\n\r\n0.7867832\r\n\r\n\r\n0.2132168\r\n\r\n\r\n0.5795924\r\n\r\n\r\n0.4204076\r\n\r\n\r\n0.8419302\r\n\r\n\r\n0.1580698\r\n\r\n\r\n0.9109622\r\n\r\n\r\n0.0890378\r\n\r\n\r\n0.4547933\r\n\r\n\r\n0.5452067\r\n\r\n\r\n0.9325001\r\n\r\n\r\n0.0674999\r\n\r\n\r\n0.1729420\r\n\r\n\r\n0.8270580\r\n\r\n\r\n0.7532123\r\n\r\n\r\n0.2467877\r\n\r\n\r\n0.8164021\r\n\r\n\r\n0.1835979\r\n\r\n\r\n0.6662097\r\n\r\n\r\n0.3337903\r\n\r\n\r\n0.6190422\r\n\r\n\r\n0.3809578\r\n\r\n\r\n0.2889425\r\n\r\n\r\n0.7110575\r\n\r\n\r\n0.8479313\r\n\r\n\r\n0.1520687\r\n\r\n\r\n0.1264501\r\n\r\n\r\n0.8735499\r\n\r\n\r\n0.3830979\r\n\r\n\r\n0.6169021\r\n\r\n\r\n0.8399914\r\n\r\n\r\n0.1600086\r\n\r\n\r\n0.1528338\r\n\r\n\r\n0.8471662\r\n\r\n\r\n0.3729621\r\n\r\n\r\n0.6270379\r\n\r\n\r\n0.2491113\r\n\r\n\r\n0.7508887\r\n\r\n\r\n0.9566130\r\n\r\n\r\n0.0433870\r\n\r\n\r\n0.3868871\r\n\r\n\r\n0.6131129\r\n\r\n\r\n0.9162998\r\n\r\n\r\n0.0837002\r\n\r\n\r\n0.5063979\r\n\r\n\r\n0.4936021\r\n\r\n\r\n0.1393546\r\n\r\n\r\n0.8606454\r\n\r\n\r\n0.7058471\r\n\r\n\r\n0.2941529\r\n\r\n\r\n0.1299578\r\n\r\n\r\n0.8700422\r\n\r\n\r\n0.9103867\r\n\r\n\r\n0.0896133\r\n\r\n\r\n0.3622388\r\n\r\n\r\n0.6377612\r\n\r\n\r\n0.7972723\r\n\r\n\r\n0.2027277\r\n\r\n\r\n0.2524625\r\n\r\n\r\n0.7475375\r\n\r\n\r\n0.3687792\r\n\r\n\r\n0.6312208\r\n\r\n\r\n0.2517045\r\n\r\n\r\n0.7482955\r\n\r\n\r\n0.7266976\r\n\r\n\r\n0.2733024\r\n\r\n\r\n0.9208382\r\n\r\n\r\n0.0791618\r\n\r\n\r\n0.8987359\r\n\r\n\r\n0.1012641\r\n\r\n\r\n0.6586531\r\n\r\n\r\n0.3413469\r\n\r\n\r\n0.7361411\r\n\r\n\r\n0.2638589\r\n\r\n\r\n0.7207294\r\n\r\n\r\n0.2792706\r\n\r\n\r\n0.8658713\r\n\r\n\r\n0.1341287\r\n\r\n\r\n0.0910796\r\n\r\n\r\n0.9089204\r\n\r\n\r\n0.1871279\r\n\r\n\r\n0.8128721\r\n\r\n\r\n0.1318369\r\n\r\n\r\n0.8681631\r\n\r\n\r\n0.8194741\r\n\r\n\r\n0.1805259\r\n\r\n\r\n0.9296778\r\n\r\n\r\n0.0703222\r\n\r\n\r\n0.1888794\r\n\r\n\r\n0.8111206\r\n\r\n\r\n0.9148847\r\n\r\n\r\n0.0851153\r\n\r\n\r\n0.9337677\r\n\r\n\r\n0.0662323\r\n\r\n\r\n0.6434955\r\n\r\n\r\n0.3565045\r\n\r\n\r\n0.3412828\r\n\r\n\r\n0.6587172\r\n\r\n\r\n0.4587399\r\n\r\n\r\n0.5412601\r\n\r\n\r\n0.2573581\r\n\r\n\r\n0.7426419\r\n\r\n\r\n0.7516383\r\n\r\n\r\n0.2483617\r\n\r\n\r\n0.7319660\r\n\r\n\r\n0.2680340\r\n\r\n\r\n0.1418407\r\n\r\n\r\n0.8581593\r\n\r\n\r\n0.8122971\r\n\r\n\r\n0.1877029\r\n\r\n\r\n0.1695376\r\n\r\n\r\n0.8304624\r\n\r\n\r\n0.7638905\r\n\r\n\r\n0.2361095\r\n\r\n\r\n0.4742153\r\n\r\n\r\n0.5257847\r\n\r\n\r\n0.8403847\r\n\r\n\r\n0.1596153\r\n\r\n\r\n0.7330562\r\n\r\n\r\n0.2669438\r\n\r\n\r\n0.7917181\r\n\r\n\r\n0.2082819\r\n\r\n\r\n0.8720718\r\n\r\n\r\n0.1279282\r\n\r\n\r\n0.1267389\r\n\r\n\r\n0.8732611\r\n\r\n\r\n0.6350556\r\n\r\n\r\n0.3649444\r\n\r\n\r\n0.7399407\r\n\r\n\r\n0.2600593\r\n\r\n\r\n0.8741648\r\n\r\n\r\n0.1258352\r\n\r\n\r\n0.8660241\r\n\r\n\r\n0.1339759\r\n\r\n\r\n0.2554399\r\n\r\n\r\n0.7445601\r\n\r\n\r\n0.1528338\r\n\r\n\r\n0.8471662\r\n\r\n\r\n0.3433892\r\n\r\n\r\n0.6566108\r\n\r\n\r\n0.6589888\r\n\r\n\r\n0.3410112\r\n\r\n\r\n0.2652359\r\n\r\n\r\n0.7347641\r\n\r\n\r\n0.2366246\r\n\r\n\r\n0.7633754\r\n\r\n\r\n0.3455043\r\n\r\n\r\n0.6544957\r\n\r\n\r\n0.6921091\r\n\r\n\r\n0.3078909\r\n\r\n\r\n0.9162961\r\n\r\n\r\n0.0837039\r\n\r\n\r\n0.4016028\r\n\r\n\r\n0.5983972\r\n\r\n\r\n0.7267600\r\n\r\n\r\n0.2732400\r\n\r\n\r\n0.1003044\r\n\r\n\r\n0.8996956\r\n\r\n\r\n0.8699004\r\n\r\n\r\n0.1300996\r\n\r\n\r\n0.9046109\r\n\r\n\r\n0.0953891\r\n\r\n\r\n0.3258607\r\n\r\n\r\n0.6741393\r\n\r\n\r\n0.7465101\r\n\r\n\r\n0.2534899\r\n\r\n\r\n0.7675051\r\n\r\n\r\n0.2324949\r\n\r\n\r\n0.6817668\r\n\r\n\r\n0.3182332\r\n\r\n\r\n0.8438136\r\n\r\n\r\n0.1561864\r\n\r\n\r\n0.1528338\r\n\r\n\r\n0.8471662\r\n\r\n\r\n0.1085500\r\n\r\n\r\n0.8914500\r\n\r\n\r\n0.5192724\r\n\r\n\r\n0.4807276\r\n\r\n\r\n0.6239067\r\n\r\n\r\n0.3760933\r\n\r\n\r\n0.6460375\r\n\r\n\r\n0.3539625\r\n\r\n\r\n0.6027468\r\n\r\n\r\n0.3972532\r\n\r\n\r\n0.1739582\r\n\r\n\r\n0.8260418\r\n\r\n\r\n0.1132057\r\n\r\n\r\n0.8867943\r\n\r\n\r\n0.7532626\r\n\r\n\r\n0.2467374\r\n\r\n\r\n0.8583470\r\n\r\n\r\n0.1416530\r\n\r\n\r\n0.2562990\r\n\r\n\r\n0.7437010\r\n\r\n\r\n0.6256820\r\n\r\n\r\n0.3743180\r\n\r\n\r\n0.4553174\r\n\r\n\r\n0.5446826\r\n\r\n\r\n0.7762246\r\n\r\n\r\n0.2237754\r\n\r\n\r\n0.7242303\r\n\r\n\r\n0.2757697\r\n\r\n\r\n0.8500709\r\n\r\n\r\n0.1499291\r\n\r\n\r\n0.8967629\r\n\r\n\r\n0.1032371\r\n\r\n\r\n0.5534839\r\n\r\n\r\n0.4465161\r\n\r\n\r\n0.4705272\r\n\r\n\r\n0.5294728\r\n\r\n\r\n0.2436154\r\n\r\n\r\n0.7563846\r\n\r\n\r\n0.7944161\r\n\r\n\r\n0.2055839\r\n\r\n\r\n0.8334619\r\n\r\n\r\n0.1665381\r\n\r\n\r\n0.1729420\r\n\r\n\r\n0.8270580\r\n\r\n\r\n0.8988484\r\n\r\n\r\n0.1011516\r\n\r\n\r\n0.2670578\r\n\r\n\r\n0.7329422\r\n\r\n\r\n0.8767651\r\n\r\n\r\n0.1232349\r\n\r\n\r\n\r\nheartXGBtestpred<-cbind(heartXGB_Pred,heartTest)\r\n\r\nheartXGBtestpred<-heartXGBtestpred%>%\r\n  mutate(pred=if_else(YES>NO,\"YES\",\"NO\"))\r\n\r\ntable(heartXGBtestpred$pred)\r\n\r\n\r\n\r\n NO YES \r\n164 203 \r\n\r\nXgbConfusion<-confusionMatrix(factor(heartXGBtestpred$pred),factor(heartXGBtestpred$prediction))\r\n\r\nggplot(as.data.frame(XgbConfusion$table))+ \r\n  geom_raster(aes(x=Reference, y=Prediction, fill=Freq)) + \r\n  geom_text(aes(x=Reference, y=Prediction, label=Freq)) +\r\n  scale_fill_gradient2( low = \"darkred\", high = \"pink\", na.value=\"black\", name = \"Freq\" )+\r\n  scale_x_discrete(name=\"Actual Class\") + \r\n  scale_y_discrete(name=\"Predicted Class\")+\r\n  ggtitle(\"Confusion is fun\")+\r\n  theme(plot.title = element_text(hjust=0.5, size=10, face='bold'))\r\n\r\n\r\n\r\n#Feature importance\r\nsummary(heartXGB)\r\n\r\n\r\n\r\n                              var    rel.inf\r\nExerciseAnginaY   ExerciseAnginaY 28.2478939\r\nCholesterol           Cholesterol 18.9408716\r\nChestPainTypeATA ChestPainTypeATA 12.0992758\r\nMaxHR                       MaxHR 11.5716161\r\nSexM                         SexM 10.4471377\r\nAge                           Age  7.0773958\r\nChestPainTypeNAP ChestPainTypeNAP  5.7688710\r\nFastingBS               FastingBS  3.2005244\r\nRestingBP               RestingBP  2.3908781\r\nChestPainTypeTA   ChestPainTypeTA  0.2555356\r\nRestingECGNormal RestingECGNormal  0.0000000\r\nRestingECGST         RestingECGST  0.0000000\r\n\r\nV<-caret::varImp(heartXGB, n.trees=500)$importance%>%\r\n  arrange(desc(Overall))\r\n\r\nggplot2::ggplot(V, aes(x=reorder(rownames(V),Overall), y=Overall)) +\r\n  geom_point( color=\"blue\", size=4, alpha=0.6)+\r\n  geom_segment( aes(x=rownames(V), xend=rownames(V), y=0, yend=Overall), \r\n                color='skyblue') +\r\n  xlab('Variable')+\r\n  ylab('Overall Importance')+\r\n  theme_light() +\r\n  coord_flip() \r\n\r\n\r\n\r\n\r\n5. Describe your results. How can this be useful\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-07T18:55:49-06:00"
    },
    {
      "path": "index.html",
      "title": "Colin Miner",
      "description": "Creating organic, GMO-free software since 1985",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Colin Miner - ACC8143\r\n          \r\n          \r\n          Home\r\n          Resume\r\n          \r\n          \r\n          Projects\r\n           \r\n          ▾\r\n          \r\n          \r\n          RSquared\r\n          Machine Learning\r\n          Final Project\r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            Colin Miner\r\n          \r\n          \r\n            \r\n              I am a data wrangler, requirements gatherer, and project conductor.\r\n            \r\n            \r\n              I am a data wrangler, requirements gatherer, and project conductor.\r\n            \r\n          \r\n\r\n          \r\n            \r\n              \r\n                  \r\n                    \r\n                      LinkedIn\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      GitHub\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                \r\n                              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                                \r\n                  \r\n                    LinkedIn\r\n                  \r\n                \r\n                                \r\n                  \r\n                    GitHub\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Email\r\n                  \r\n                \r\n                              \r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2021-12-07T19:23:49-06:00"
    },
    {
      "path": "ML.html",
      "title": "Machine Learning",
      "description": "Random Forests\n",
      "author": [
        {
          "name": "Colin Miner",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\n\r\n\r\nImagine you are in a class of 50 students and the teacher is going to ask a question about the homework. If the teacher randomly picks one student there is a chance of picking someone who will give the wrong answer. But if the teacher has everyone answer the question, and then picks the answer with the most votes, there is a higher chance of getting the right answer.\r\nRandom Forests are very similar. They choose an answer that has the most votes out of a group of Decision Trees. A decision tree is a way of trying to predict something based off of data by answering True or False questions. For example if you had a basket of different foods and wanted a way to have a computer tell if any piece of food was an apple. You could first ask “Is it a fruit?” If the answer is no, then it isn’t an apple. But if the answer is yes, you could then ask “is it round?”, “is it red?”, “is it sweet?”, etc.\r\nA random forest takes lots of these decision trees and has each of them use different sets of questions about the food to try and figure out which sets of questions are best at getting the right answer. Then it uses the prediction with the most votes. This way if any one decision tree is really wrong in how it predicts, it won’t tips the scales too much.\r\nIn the accounting world this can be used to try and predict customers who can be immediately approved for a loan, or which loans might need someone to take a closer look at the deal before approving it.\r\nThis example uses data about people dining at a restaurant to try and predict if any given diner is male or female, based on how much they tipped, how big the bill was, and how many people were in the group.\r\n\r\n\r\n    set.seed(1)\r\n    #lets split the data 60/40\r\n     \r\n    trainIndex <- createDataPartition(tips$sex, p = .6, list = FALSE, times = 1)\r\n\r\n    #grab the data\r\n    tipsTrain <- tips[ trainIndex,]\r\n    tipsTest  <- tips[-trainIndex,]\r\n\r\n    set.seed(1)\r\n\r\n    tipsRF<- train(\r\n      form = factor(sex) ~ total_bill+tip+size,\r\n      data = tipsTrain,\r\n      #here we add classProbs because we want probs\r\n      trControl = trainControl(method = \"cv\", number = 10,\r\n                               classProbs =  TRUE),\r\n      method = \"rf\",\r\n      tuneLength = 2)\r\n\r\n    tipsRF_Pred<-predict(tipsRF,tipsTest,type=\"prob\")\r\n    tipsrftestpred<-cbind(tipsRF_Pred,tipsTest)\r\n    tipsRF\r\n\r\n\r\nRandom Forest \r\n\r\n148 samples\r\n  3 predictor\r\n  2 classes: 'Female', 'Male' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 133, 134, 133, 132, 134, 134, ... \r\nResampling results across tuning parameters:\r\n\r\n  mtry  Accuracy   Kappa      \r\n  2     0.5672619  0.009170983\r\n  3     0.5739286  0.042797266\r\n\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final value used for the model was mtry = 3.\r\n\r\n    tipsrftestpred<-tipsrftestpred%>%\r\n      mutate(prediction=ifelse(Male>=.5,\"Male\",\"Female\"))\r\n\r\n    confusionMatrix(factor(tipsrftestpred$prediction),factor(tipsrftestpred$sex))\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction Female Male\r\n    Female     10   18\r\n    Male       24   44\r\n                                          \r\n               Accuracy : 0.5625          \r\n                 95% CI : (0.4575, 0.6636)\r\n    No Information Rate : 0.6458          \r\n    P-Value [Acc > NIR] : 0.9636          \r\n                                          \r\n                  Kappa : 0.004           \r\n                                          \r\n Mcnemar's Test P-Value : 0.4404          \r\n                                          \r\n            Sensitivity : 0.2941          \r\n            Specificity : 0.7097          \r\n         Pos Pred Value : 0.3571          \r\n         Neg Pred Value : 0.6471          \r\n             Prevalence : 0.3542          \r\n         Detection Rate : 0.1042          \r\n   Detection Prevalence : 0.2917          \r\n      Balanced Accuracy : 0.5019          \r\n                                          \r\n       'Positive' Class : Female          \r\n                                          \r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-07T19:32:31-06:00"
    },
    {
      "path": "Resume.html",
      "title": "Resume",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\n\r\n\r\nColin Miner\r\nSoftware Developer\r\n\r\ncjm131@msstate.edu\r\nSkills Summary\r\nEducational History\r\nData warehousing and analytics\r\nUniversity of Southern Mississippi\r\nSoftware Development\r\nBachelor of Science, Computer Science\r\nProcess Improvement\r\nHonors College\r\nProject Management\r\nMay 2007\r\nVB/C#/SQL\r\n\r\nCrystal Reports\r\n\r\nWork Experience\r\nBlossman Gas, Inc\r\nJune 2006 - Present\r\nResponsible for all aspects of application development including requirements gathering, design, development,testing, implementation, and maintenance\r\nTrain team members in company best practices and programming techniques\r\nCoordinate programming projects with other departments\r\nRegularly deliver financial and productivity reports to company officers\r\nTroubleshoot data and software problems\r\nAutomated and maintain the generation, printing, and mailing of company billing documents\r\nCreated an SMS texting process to alert customers of upcoming/completed deliveries and handle incoming customer text requests, reducing workload on call center personnel\r\nDeveloped multiple interfaces to parse payment and delivery data and post to back office software\r\nCreated internal tool suite including customer financing applications, propane hedging management, parts ordering, and interface administration Responsible for analyzing and integrating data from company acquisitions\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-07T19:29:32-06:00"
    },
    {
      "path": "RSquared.html",
      "title": "R Squared",
      "description": "R Squared as a measure of model fit\n",
      "author": [
        {
          "name": "Colin Miner",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\nR-squared can be arbitrarily close to 1 when the model is totally wrong.\r\nWhen a measure indicates that a model is performing poorly, it will prompt the user to investigate the model for problems. This may waste time, but is less of a problem than if the measure gives a false positive and makes it seem like the model is performing well. This can cause a user to continue on with the bad model and create more problems down the road.\r\n\r\n\r\nset.seed(1)\r\n# our predictor is data from an exponential distribution\r\nx <- rexp(50,rate=0.005)\r\n# non-linear data generation\r\ny <- (x-1)^2 * runif(50, min=0.8, max=1.2) \r\n\r\n# clearly non-linear\r\nplot(x,y)             \r\n\r\n\r\n\r\n\r\n\r\n\r\nsummary(lm(y ~ x))$r.squared\r\n\r\n\r\n[1] 0.8485146\r\n\r\nEven adjusted and predictive R^2 are not much better:\r\n\r\n\r\n#Adjusted R^2\r\nsummary(lm(y ~ x))$adj.r.squared\r\n\r\n\r\n[1] 0.8453587\r\n\r\n#PRESS - predicted residual sums of squares\r\n\r\nPRESS <- function(linear.model) {\r\n  #' calculate the predictive residuals\r\n  pr <- residuals(linear.model)/(1-lm.influence(linear.model)$hat)\r\n  #' calculate the PRESS\r\n  PRESS <- sum(pr^2)\r\n  \r\n  return(PRESS)\r\n}\r\n\r\npred_r_squared <- function(linear.model) {\r\n  #' Use anova() to get the sum of squares for the linear model\r\n  lm.anova <- anova(linear.model)\r\n  #' Calculate the total sum of squares\r\n  tss <- sum(lm.anova$'Sum Sq')\r\n  # Calculate the predictive R^2\r\n  pred.r.squared <- 1-PRESS(linear.model)/(tss)\r\n  \r\n  return(pred.r.squared)\r\n}\r\n\r\nmodel <- lm(y ~ x)  \r\npred_r_squared(model)\r\n\r\n\r\n[1] 0.7700853\r\n\r\nThere is no perfect solution, but relying on a single measure for model fit always leaves a chance of something going wrong. Using multiple measures helps, as does simply graphing the data and visually judging the model.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-07T19:30:17-06:00"
    }
  ],
  "collections": []
}
